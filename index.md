# Workshop Summary
<p align="justify">
When researchers and practitioners, as well as policy makers and the public, discuss the impacts of deep learning systems, they draw upon multiple conceptual frames that do not sit easily beside each other. Questions of algorithmic fairness arise from a set of concerns that are similar, but not identical, to those that circulate around AI safety, which in turn overlap with, but are distinct from, the questions that motivate work on AI ethics, and so on. Robust bodies of research on privacy, security, transparency, accountability, interpretability, explainability, and opacity are also incorporated into each of these frames and conversations in variable ways. These frames reveal gaps that persist across both highly technical and socially embedded approaches, and yet collaboration across these gaps has proven challenging.</p>

<p align="justify">Fairness, Ethics, and Safety in AI each draw upon different disciplinary prerogatives, variously centering applied mathematics, analytic philosophy, behavioral sciences, legal studies, and the social sciences in ways that make conversation between these frames fraught with misunderstandings. These misunderstandings arise from a high degree of linguistic slippage between different frames, and reveal the epistemic fractures that undermine valuable synergy and productive collaboration. This workshop focuses on ways to translate between these ongoing efforts and bring them into necessary conversation in order to understand the profound impacts of algorithmic systems in society. </p>

<p align="justify">Efforts to understand powerful technosocial systems are not new. But now, a broad range of stakeholders are grappling with the impacts of such systems brought about through the development and deployment of AI technologies. They bring disparate disciplinary framings to this effort, which produce very different descriptions of the problems to be solved, as well as potential solutions. As a result, this fractured set of conversations make it difficult for technologists and researchers, as well as policy and decision-makers in academia, government, and industry, to understand the problem space of algorithmic impacts and the range of possible interventions.</p>

This workshop will:
- Bring together technical and non-technical researchers working across different frames on cross-cutting panels in order to work toward understanding the range of perspectives in AI Ethics, Fairness, and Safety. 
- Present invited and contributed talks on state of the art algorithmic approaches to fairness and safety in AI.
- Present invited and contributed talks on the current epistemic challenges facing those who work in AI Ethics, Fairness, and Safety.
- Move beyond the conventional “toy” problems of AI Fairness (e.g. algorithmic risk scoring), Ethics (e.g. the trolley problem), and Safety (e.g. paperclip maximizers) to highlight real-world cases of algorithmic impacts that call for careful study by those working in AI Ethics, Fairness, and Safety. 

# Workshop Schedule
<p align="justify"><i>Fri Dec 13th 08:00 AM -- 06:00 PM @ East Meeting Rooms 8 + 15</i></p>
<p><b>08:00 AM Opening Remarks</b><br>
<i>TBD</i></p>
<p><b>08:15 AM Invited Talk</b><br>
<i>Yoshua Bengio</i></p>
<p><b>08:45 AM Approaches to Understanding AI</b> (Discussion Panel)<br>
<i>Yoshua Bengio, Roel Dobbe, Madeleine Elish, Joshua Kroll, Jacob Metcalf<br>
Jack Poulson -- moderator</i></p>
<p><b>09:45 AM Spectrogram</b> (Activity)<br>
<i>Emanuel Moss</i></p>
<p><b>10:00 AM Coffee Break</b></p>
<p><b>10:30 AM Detecting and Documenting AI Impacts</b> (Discussion Panel)<br>
<i>Melissa Roman, Alexa Hagerty, Fabian Rogers, Friederike Schuur, Jacob Snow<br>
Madeleine Elish -- moderator</i></p>
<p><b>11:30 AM Responsibilities</b> (Discussion Panel)<br>
<i>RAlex Hanna, Been Kim, Liz O'Sullivan, Friederike Schuur, Andrew Smart<br>
Jacob Metcalf -- moderator</i></p>
<p><b>12:30 PM Lunch Break</b></p>
<p><b>02:00 PM A Conversation with Meredith Whittaker</b> (Interview)<br>
<i>Meredith Whittaker<br>
Mona Sloane -- moderator</i></p>
<p><b>02:45 PM Global Implications</b> (Discussion Panel)<br>
<i>Eirini Malliaraki, Jack Poulson, Vinod Prabhakaran, Mona Sloane<br>
Alexa Hagerty -- moderator</i></p>
<p><b>03:45 PM Coffee Break</b></p>
<p><b>04:30 PM Solutions</b> (Discussion Panel)<br>
<i>Melissa Roman, Lily Hu, Brandeis Marshall, Fabian Rogers, Friederike Schuur<br>
Emanuel Moss -- moderator</i></p>
